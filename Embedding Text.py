# -*- coding: utf-8 -*-
"""latihan9_dicoding_Embedding Kata.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UIhsHOpccCn_LrJPW00nCcjb4E9cANSH
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow_datasets as tfds

tfds.disable_progress_bar()

embedding_layer = layers.Embedding(1000, 5)

result = embedding_layer(tf.constant([1,2,3]))
result.numpy()

result = embedding_layer(tf.constant([[0,1,2],[3,4,5]]))
result.shape

(train_data, test_data), info = tfds.load(
    'imdb_reviews/subwords8k',
    split =(tfds.Split.TRAIN, tfds.Split.TEST),
    with_info=True, as_supervised=True
)

encoder = info.features['text'].encoder
encoder.subwords[:20]

train_batches = train_data.shuffle(1000).padded_batch(10)
test_batches = train_data.shuffle(1000).padded_batch(10)

train_batch, train_labels = next(iter(train_batches))
train_batch.numpy()

embedding_dim = 16
model = keras.Sequential([
                          layers.Embedding(encoder.vocab_size, embedding_dim),
                          layers.GlobalAveragePooling1D(),
                          layers.Dense(16, activation='relu'),
                          layers.Dense(1)
])

model.summary()

#kumpulkan dan latih modelnya
model.compile(optimizer='adam',
              loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

#melatih dataset dan data train
history = model.fit(
    train_batches,
    epochs=5,
    validation_data = test_batches,
    validation_steps=20
)

import matplotlib.pyplot as plt

history_dict = history.history

acc = history_dict['accuracy']
val_acc = history_dict['val_accuracy']
loss = history_dict['loss']
val_loss = history_dict['val_loss']

epochs = range(1, len(acc) +1)

plt.figure(figsize=(12,9))
plt.plot(epochs, loss, 'bo', label = 'Trainig Loss')
plt.plot(epochs, val_loss, 'b', label = 'Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.figure(figsize=(12,9))
plt.plot(epochs, acc, 'bo', label='Training Acc')
plt.plot(epochs, val_acc, 'b', label='Validation Acc')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.xlabel('Accuracy')
plt.legend(loc='lower right')
plt.ylim((0.5,1))
plt.show()

e=model.layers[0]
weights=e.get_weights()[0]
print(weights.shape)

import io

encoder=info.features['text'].encoder
out_v = io.open('vec_tsv','w', encoding='utf-8')
out_m = io.open('meta.tsv', 'w', encoding='utf-8')

for num,word in enumerate(encoder.subwords):
  vec=weights[num+1]
  out_m.write(word+"\n")
  out_v.write('\t'.join([str(x) for x in vec]) + "\n")
out_v.close()
out_m.close()

